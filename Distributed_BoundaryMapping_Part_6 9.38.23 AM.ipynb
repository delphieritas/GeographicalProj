{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab notebooks have an idle timeout of 90 minutes and absolute timeout of 12 hours. \n",
        "Colab Pro+ supports continuous code execution for up to 24 hours if you have sufficient compute units."
      ],
      "metadata": {
        "id": "iY2o-Zmp6B8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Electoral Boundary 2020](https://data.gov.sg/dataset/electoral-boundary_2020)"
      ],
      "metadata": {
        "id": "axQ8KfGxxsFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Singapore HDB Postal Code Mapper (2018) [link text](https://www.kaggle.com/datasets/mylee2009/singapore-postal-code-mapper)\n",
        "\n",
        "A list of all HDB postal code and address (latitude, longtitude, proper address) extracted from:\n",
        "\n",
        "Postal Code - HDB Resale Flat Price from data.sg (https://data.gov.sg/dataset/resale-flat-prices)\n",
        "\n",
        "Proper address/ latitude/longitude from onemap.sg api (https://docs.onemap.sg/)\n",
        "\n",
        "Python codes used to extract information can be found here: https://github.com/mylee16/onemap-api"
      ],
      "metadata": {
        "id": "OTC4zS9sx1i5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Master Plan 2019 Subzone Boundary (No Sea)](https://data.gov.sg/dataset/master-plan-2019-subzone-boundary-no-sea)"
      ],
      "metadata": {
        "id": "KyelV_n8x7k9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Master Plan 2019 Planning Area Boundary](https://data.gov.sg/dataset/master-plan-2019-planning-area-boundary-no-sea)"
      ],
      "metadata": {
        "id": "sYmR3ubeyXAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --quiet geopandas\n",
        "import geopandas as gpd \n",
        "import fiona\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "# download all zipped compressed folders\n",
        "\n",
        "# Master Plan 2019 Subzone Boundary (No Sea)\n",
        "!wget -O data4.zip https://data.gov.sg/dataset/c754450d-ecbd-4b7d-8dc1-c07ee842c6d1/download\n",
        "# Master Plan 2019 Planning Area Boundary\n",
        "# !wget -O data5.zip https://data.gov.sg/dataset/40267ab6-7c08-45c4-b777-a3b10e68f1c8/download\n",
        "\n",
        "# Electoral Boundary 2020\n",
        "!wget -O data7.zip https://data.gov.sg/dataset/6241ae7f-6dfe-4351-8570-611357d1a90e/download\n",
        "\n",
        "# unzip all\n",
        "!unzip data4.zip\n",
        "# !unzip data5.zip\n",
        "!unzip data7.zip\n",
        "# data7\n",
        "!unzip electoral-boundary-dataset.kmz\n",
        "\n",
        "# CDC dataset from YY\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "!gdown 1hPxde9qZwt297SsBnkDyb9k4YoYJWDz7\n",
        "!gdown 127OyOlsGJV5sOX0ej3dINhE8c7gn3_sE\n",
        "!gdown 1tv32HHtH3A1ZKcj76xvXZavShCIZmjYG\n",
        "!gdown 1ZLTC3j8gtfiYYih5ffDpP0QbECtOTFrY\n",
        "!gdown 1Q51nrjV-WkdiJDJSOapSkNg4cE6xTBSI\n",
        "\n",
        "\n",
        "# rename files to make it clearer\n",
        "# !mv oldnamefile1 newnamefile1\n",
        "\n",
        "\n",
        "# data4\n",
        "!mv master-plan-2019-subzone-boundary-no-sea-kml.kml URA2019-Subzone.kml   \n",
        "!mv master-plan-2019-subzone-boundary-no-sea-geojson.geojson URA2019-Subzone.geojson   \n",
        "\n",
        "# data5\n",
        "# !mv planning-boundary-area.kml URA2019-Plan.kml     #dataset no longer needed\n",
        "\n",
        "# data7\n",
        "!mv 62C4422C0D5147ED8C28FA94627357DB.xsl electoral2020.xsl\n",
        "!mv doc.kml electoral2020.kml\n",
        "\n",
        "# data8\n",
        "# PA_CDC_Boundary_2020.kml\n",
        "\n",
        "# remove unnecessary files\n",
        "import os\n",
        "\n",
        "contents = os.listdir()\n",
        "\n",
        "for i in contents:\n",
        "    if \".zip\" in i:\n",
        "        os.remove(i)\n",
        "    if \".txt\" in i:\n",
        "        os.remove(i)\n",
        "    if \".kmz\" in i:\n",
        "        os.remove(i)\n",
        "    if \".lyr\" in i:\n",
        "        os.remove(i)\n",
        "    if \".log\" in i:\n",
        "        os.remove(i)\n",
        "\n",
        "# download 200k addresses/postal codes\n",
        "!gdown 1AiVKnBjWelL4O7nUCFBRg99Ns3i9kM_n\n",
        "\n",
        "# download YN RHS files\n",
        "# all\n",
        "!gdown 19NdmAcqDQpf-Oci39DCypAy-gFZR24W-\n",
        "\n",
        "# converts kml files to json files\n",
        "!pip install kml2geojson\n",
        "\n",
        "!k2g -sf PA_CDC_Boundary.json PA_CDC_Boundary_2020.kml ./\n",
        "# !k2g -sf URA2019-Plan.json URA2019-Plan.kml ./\n",
        "!k2g -sf URA2019-Subzone.json URA2019-Subzone.kml ./\n",
        "# !k2g -sf community-in-bloom-cib.json community-in-bloom-cib.kml ./\n",
        "!k2g -sf electoral2020.json electoral2020.kml ./\n",
        "\n",
        "# RHS kml to json\n",
        "!k2g -sf RHS_3_regions.json RHS_3_regions.kml ./\n"
      ],
      "metadata": {
        "id": "QQkLgAx0WuWy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "import time\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "def pipeline(df):\n",
        "    '''\n",
        "        Input: original 200k df (with all columns)\n",
        "        Output: transformed 200k df (only required information)\n",
        "    '''\n",
        "\n",
        "    # masterplan for all the data sets (how to use each dataset)\n",
        "    masterplan1 = {\n",
        "        \"electoral2020.kml\" : \"ELD_ELECTORAL_DIVISION_NAME\",\n",
        "        \"RHS_3_regions.kml\" : \"MOH_RHS_ZONE_NAME\",\n",
        "        \"URA2019-Subzone.kml\" : \"URA\",\n",
        "        \"PA_CDC_Boundary_2020.kml\" : \"CDC\"\n",
        "    }\n",
        "\n",
        "    masterplan2 = {\n",
        "        \"URA2019-Subzone.kml\" : {\"SUBZONE_N\" : \"URA_PLANNING_SUBZONE_NAME\",\n",
        "                                \"PLN_AREA_N\" : \"URA_PLANNING_AREA_NAME\",\n",
        "                                \"REGION_N\" : \"URA_\"},\n",
        "        \"PA_CDC_Boundary_2020.kml\" : {\"CDC_NAME\" : \"CDC Name\"}\n",
        "    }\n",
        "\n",
        "    files = [\"URA2019-Subzone.kml\", \"PA_CDC_Boundary_2020.kml\"]\n",
        "\n",
        "    masterplan3 = {}\n",
        "\n",
        "    def get_URA_Region(name=\"kml_1\"):\n",
        "        '''Get URA region using the masterplan'''\n",
        "        try:\n",
        "            plan = masterplan3[\"URA2019-Subzone.kml\"]\n",
        "            return plan[name][\"URA_\"]\n",
        "        except:\n",
        "            return 'N.A.'\n",
        "\n",
        "    def get_URA_Planning_Area(name=\"kml_1\"):\n",
        "        '''Get URA planning area using the masterplan'''\n",
        "        try:\n",
        "            plan = masterplan3[\"URA2019-Subzone.kml\"]\n",
        "            return plan[name][\"URA_PLANNING_AREA_NAME\"]\n",
        "        except:\n",
        "            return 'N.A.'\n",
        "\n",
        "    def get_URA_Subzone(name='kml_1'):\n",
        "        '''Get URA subzone using the masterplan'''\n",
        "        try:\n",
        "            plan = masterplan3[\"URA2019-Subzone.kml\"]\n",
        "            return plan[name][\"URA_PLANNING_SUBZONE_NAME\"]\n",
        "        except:\n",
        "            return 'N.A.'\n",
        "\n",
        "    def get_CDC_Name(name=\"kml_1\"):\n",
        "        '''Get CDC name using the masterplan'''\n",
        "        try:\n",
        "            plan = masterplan3[\"PA_CDC_Boundary_2020.kml\"]\n",
        "            return plan[name][\"CDC Name\"]\n",
        "        except:\n",
        "            return 'N.A.'\n",
        "            \n",
        "    def kml_to_df(file):\n",
        "        try:\n",
        "            df = gpd.read_file(file, driver='KML')\n",
        "        except:\n",
        "            fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
        "            df = gpd.read_file(file, driver='KML')\n",
        "        return df\n",
        "\n",
        "    def get_attributes_value(html_description, attribute_name='SUBZONE_N'):\n",
        "        def row_transform(row):\n",
        "            return pd.DataFrame(pd.read_html(row)[0])\n",
        "        def html_df(html_description):\n",
        "            row = row_transform(html_description)\n",
        "            return row[row['Attributes']==attribute_name]\n",
        "        return html_df(html_description).values[0][1]\n",
        "\n",
        "    for file_name in files:\n",
        "        file_kml = kml_to_df(file_name)\n",
        "        file_dict = {}\n",
        "\n",
        "        plan = masterplan2[file_name]\n",
        "\n",
        "        for name in file_kml[\"Name\"]: # kml1, kml2, ...\n",
        "            # want to find the URA_plan..\n",
        "            description = file_kml[file_kml[\"Name\"]==name][\"Description\"].reset_index(drop=True)[0]\n",
        "            file_dict[name] = dict([(new_colname, get_attributes_value(html_description=description, \n",
        "                            attribute_name=colname)) for colname, new_colname in masterplan2[file_name].items()])\n",
        "        masterplan3[file_name] = file_dict\n",
        "\n",
        "    def digit_extend(POSTAL_CODE):\n",
        "        if len(str(POSTAL_CODE)) != 6:\n",
        "          POSTAL_CODE = '0' + str(POSTAL_CODE)\n",
        "        return POSTAL_CODE\n",
        "\n",
        "    def add_lnglat(df, x_name=\"X_ADDR\", y_name=\"Y_ADDR\"):\n",
        "        '''\n",
        "        Converts (X_ADDR, Y_ADDR) to (longitude, latitude) using OneMap API\n",
        "        Add new columns lng & lat to df\n",
        "        '''\n",
        "        list_of_lnglat = []\n",
        "        for row in df.iloc:\n",
        "            x, y = row[x_name], row[y_name]\n",
        "            url = f\"https://developers.onemap.sg/commonapi/convert/3414to4326?X={x}4&Y={y}\"\n",
        "            # hdr = {'User-Agent': 'Mozilla/5.0'}\n",
        "            hdr = {\"User-Agent\": \"pandas\"}\n",
        "            resp = requests.get(url, headers=hdr)\n",
        "            extract = json.loads(resp.content)\n",
        "            lng = extract['longitude']\n",
        "            lat = extract['latitude']\n",
        "            list_of_lnglat.append([lng, lat])\n",
        "        # transpose list_of_lnglat, then list[0] is lng, list[1] is lat\n",
        "        transposed = list(map(list, zip(*list_of_lnglat)))\n",
        "        df[\"LONG\"] = transposed[0]\n",
        "        df[\"LAT\"] = transposed[1]\n",
        "        return df\n",
        "\n",
        "    def get_pip (gdf, regions, new_colname):\n",
        "        '''\n",
        "        Point in Polygon\n",
        "        Input:\n",
        "            df - dataframe with geometry POINT\n",
        "            regions - dataframe with geometry POLYGON/MULTIPOLYGON\n",
        "        Output:\n",
        "            df - original dataframe + each row with info on regions\n",
        "        '''\n",
        "        r_list = list(regions.Name)\n",
        "        #create empty dataframe\n",
        "        df = pd.DataFrame().reindex_like(gdf).dropna()\n",
        "        for r in r_list:\n",
        "            #get geometry for specific region\n",
        "            pol = (regions.loc[regions.Name==r])\n",
        "            pol.reset_index(drop = True, inplace = True)\n",
        "            #identify those records from gdf that are intersecting with the region polygon\n",
        "            pip_mask = gdf.within(pol.loc[0, 'geometry'])\n",
        "\n",
        "            gdf.loc[pip_mask, new_colname] = r\n",
        "        return gdf\n",
        "\n",
        "    # add latitude & longitude columns using OneMap API\n",
        "    df = add_lnglat(df)\n",
        "\n",
        "    # add geopandas Point as column\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.LONG,df.LAT))\n",
        "\n",
        "\n",
        "    for file, plan in masterplan1.items():\n",
        "        kml_df = kml_to_df(file)\n",
        "        gdf = get_pip(gdf, kml_df, new_colname=plan)\n",
        "\n",
        "    # Add URA Region\n",
        "    gdf[\"URA_REGION_NAME\"] = gdf.apply(lambda row: get_URA_Region(row.URA), axis=1)\n",
        "\n",
        "    # Add URA Subzone\n",
        "    gdf[\"URA_PLANNING_SUBZONE_NAME\"] = gdf.apply(lambda row: get_URA_Subzone(row.URA), axis=1)\n",
        "\n",
        "    # Add URA Planning Area\n",
        "    gdf[\"URA_PLANNING_AREA_NAME\"] = gdf.apply(lambda row: get_URA_Planning_Area(row.URA), axis=1)\n",
        "\n",
        "    # Add CDC Name\n",
        "    gdf[\"CDC_NAME\"] = gdf.apply(lambda row: get_CDC_Name(row.CDC), axis=1)\n",
        "\n",
        "    # digit add postal codes, padding postcodes to 6-digit string object\n",
        "    gdf[\"POSTAL_ADDR\"] = gdf.apply(lambda row: digit_extend(row.POSTAL_CODE), axis=1)\n",
        "    \n",
        "    mapping = {\n",
        "        'East RHS': 'Singapore Health Services',\n",
        "        'Central RHS': 'National Healthcare Group',\n",
        "        'West RHS': 'National University Health System'\n",
        "    }\n",
        "\n",
        "    gdf['MOH_RHS_ZONE_NAME'] = gdf['MOH_RHS_ZONE_NAME'].map(mapping)\n",
        "    gdf.rename(columns={\n",
        "    \"LAST_UPD_DT\": \"REFERENCE_DT\",\n",
        "    }, inplace=True)\n",
        "    \n",
        "    # final dropping of redundant columns\n",
        "    gdf = gdf[['LAT','LONG',\n",
        "               'BUILDING_NAME',\n",
        "               'HOUSE_BLK_NO',\n",
        "               'ROAD_NAME',\n",
        "               'POSTAL_ADDR',\n",
        "               'MULTI_ADDR_IND',\n",
        "               'CDC_NAME',\n",
        "               'ELD_ELECTORAL_DIVISION_NAME',\n",
        "               'URA_REGION_NAME',\n",
        "               'URA_PLANNING_AREA_NAME',\n",
        "               'URA_PLANNING_SUBZONE_NAME',\n",
        "               'MOH_RHS_ZONE_NAME',\n",
        "               'REFERENCE_DT']]\n",
        "    # convert LAST_UPD_DT datetime into REFERENCE_DT date\n",
        "    gdf['REFERENCE_DT'] = pd.to_datetime(gdf['REFERENCE_DT']).dt.date\n",
        "    # save processed file\n",
        "    if 'Generated.csv' not in glob.glob(os.path.join('', \"*.csv\")):\n",
        "        gdf.to_csv(\"Generated.csv\", mode=\"a\", index=True, header=True)\n",
        "    else:\n",
        "        gdf.to_csv(\"Generated.csv\", mode=\"a\", index=True, header=False)\n",
        "    # get a list of outliers\n",
        "    gdf.query('ELD_ELECTORAL_DIVISION_NAME == \"N.A.\" or \\\n",
        "              URA_REGION_NAME == \"N.A.\" or \\\n",
        "              URA_PLANNING_AREA_NAME == \"N.A.\" or \\\n",
        "              URA_PLANNING_SUBZONE_NAME == \"N.A.\" or \\\n",
        "              MOH_RHS_ZONE_NAME == \"N.A.\"'\\\n",
        "              ).to_csv(\"Outliers.csv\")\n",
        "    return gdf"
      ],
      "metadata": {
        "id": "T5a6MLxuRTkr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    bulk_series = 6\n",
        "\n",
        "    bulk = 30000\n",
        "    batch = 300\n",
        "    start = int(bulk*bulk_series/batch)\n",
        "    end = int(bulk*(bulk_series+1)/batch)\n",
        "    csv_file_path = '200kpostal_xy.csv'\n",
        "    try:\n",
        "        os.remove('Generated.csv')\n",
        "    except:\n",
        "        pass\n",
        "    df = pd.read_csv(csv_file_path, on_bad_lines='skip')\n",
        "\n",
        "    out = display((start*batch, (end+1)*batch), display_id=True)\n",
        "    for ii in range(start, end):\n",
        "        out.update(progress(ii*batch, (end+1)*batch))\n",
        "        if ii*batch <=len(df):\n",
        "            test_df = pipeline(df[ii*batch:(ii+1)*batch])"
      ],
      "metadata": {
        "id": "YoAcWadE71-B"
      },
      "execution_count": 52,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}